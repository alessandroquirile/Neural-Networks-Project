# Neural-Networks-Project
Parte A: Per qualsiasi scelta delle funzioni di attivazione (unica per ogni strato) e per qualsiasi scelta della funzione di costo (sum of squares e
cross-entropy con e senza softmax) progettare ed implementare funzioni per la forward propagation
e per la backpropagation per una rete neurale multistrato.

Parte B: si estragga un dataset raw dal database MNIST e lo si divida opportunamente in training, validation e test set. Fissata la discesa del
gradiente con momento come algoritmo di aggiornamento dei pesi, si studi l'apprendimento di una rete neurale shallow al variare del learning rate
e del coefficiente del momento per almeno cinque diverse dimensioni dello strato interno.
Fissare tutte le altre scelte come, ad esempio, le funzioni di output.
